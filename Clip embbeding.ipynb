{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJgDlcCQJDDdzfwBpoA4Q4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rb58853/ML-RSI-Images/blob/main/Clip%20embbeding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8KRAwdK9WN_I"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import CLIPProcessor, CLIPModel\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "jmpjfq_gXlmV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_embedding(image):\n",
        "    image_process = processor(\n",
        "       text=None,\n",
        "       images=image,\n",
        "       return_tensors=\"pt\"\n",
        "    )[\"pixel_values\"].to(device)\n",
        "\n",
        "    embedding = model.get_image_features(image_process)\n",
        "    # print (embedding)\n",
        "    # return embedding\n",
        "    embedding_as_np = embedding.cpu().detach().numpy()\n",
        "    return embedding\n",
        "    # return embedding_as_np"
      ],
      "metadata": {
        "id": "_H8OsXRQW6Ru"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_text_embedding(text):\n",
        "    image =  Image.new('RGB', (10, 10), color = (0, 0, 0))\n",
        "    encoded_text = processor(\n",
        "        text = [text],\n",
        "        images = image,\n",
        "        padding=True,\n",
        "        # truncation=True,\n",
        "        # max_length=100,\n",
        "        return_tensors='pt').to(device)\n",
        "\n",
        "    outputs = model(**encoded_text)\n",
        "    text_embeds = outputs['text_embeds']\n",
        "    text_embedding_as_np = text_embeds.cpu().detach().numpy()\n",
        "    return text_embeds\n",
        "    # return text_embedding_as_np\n",
        "\n",
        "    # pooler_output = outputs['text_model_output']['pooler_output']\n",
        "    # return pooler_output"
      ],
      "metadata": {
        "id": "nEUoy8JScSlf"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    vec1 = vec1.cpu().detach().numpy()\n",
        "    vec2 = vec2.cpu().detach().numpy()\n",
        "    vec1 = vec1[0]\n",
        "    vec2 = vec2[0]\n",
        "    return 1 - cosine(vec1, vec2)"
      ],
      "metadata": {
        "id": "hDe7RObFiZgh"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = Image.open('image_3.jpg')\n",
        "# text = \"a cartoon dog and a cat siting in a orange couch. Cartoon dog with a blue collar and brown nose. a gray and white cat with a smile on its face\"\n",
        "text = \"a cartoon dog and a cat siting in a orange couch\"\n",
        "text = 'orange couch dog cat cartoon'\n",
        "\n",
        "image_embedding = get_image_embedding(image)\n",
        "text_embedding = get_text_embedding(text)"
      ],
      "metadata": {
        "id": "wFdaatFljFEV"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cosine_similarity(image_embedding, text_embedding))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqQQ_33QihYa",
        "outputId": "04366518-6173-4e26-92d2-fd852d6301bb"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3433797061443329\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(embeddings):\n",
        "   norms = embeddings.norm(p=2, dim=-1, keepdim=True)\n",
        "   return embeddings / norms\n",
        "\n",
        "def calculate_similarity(text_embedding, image_embedding):\n",
        "   text_embedding = normalize(text_embedding)\n",
        "   image_embedding = normalize(image_embedding)\n",
        "   similarity = torch.matmul(text_embedding, image_embedding.t())\n",
        "   return similarity\n"
      ],
      "metadata": {
        "id": "wBwXv0cxkp4F"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(calculate_similarity(image_embedding, text_embedding))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sI53barFkyVe",
        "outputId": "50b72a9a-a890-41c2-8e4e-aac4ebd132ae"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3434]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    }
  ]
}