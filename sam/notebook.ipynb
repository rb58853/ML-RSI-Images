{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### install dependences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tool: create image from a input mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def mask_image(mask, raw_image):\n",
    "    weigth, heigth = raw_image.size\n",
    "    new_image = Image.new('RGB', (weigth, heigth))\n",
    "    for i in range (len(raw_image)):\n",
    "        for j in range (len(raw_image[i])):\n",
    "            if mask[i][j]:\n",
    "                new_image[i][j] = raw_image[i][j]\n",
    "            else:\n",
    "                new_image[i][j] = 0\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with SAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### import dependences and model from hugginface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import SamModel, SamProcessor\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SamModel.from_pretrained(\"facebook/sam-vit-huge\").to(device)\n",
    "processor = SamProcessor.from_pretrained(\"facebook/sam-vit-huge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### select and import image by process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_url = \"https://huggingface.co/ybelkada/segment-anything/resolve/main/assets/car.png\"\n",
    "\n",
    "raw_image = Image.open(requests.get(img_url, stream=True).raw).convert(\"RGB\")\n",
    "input_points = [[[450, 600]]]  # 2D location of a window in the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### masks from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(raw_image, input_points=input_points, return_tensors=\"pt\").to(device)\n",
    "outputs = model(**inputs)\n",
    "\n",
    "#Estas son mascaras booleanas True implica que el pixel en cuestion interesa, y False implica que no es de interes, es Fondo de esa capa\n",
    "masks = processor.image_processor.post_process_masks(\n",
    "    outputs.pred_masks.cpu(), inputs[\"original_sizes\"].cpu(), inputs[\"reshaped_input_sizes\"].cpu()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print images shortcuts. \n",
    "once we have a masks of the input image, for each mask we will print the image that is in this position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i, mask in enumerate(masks):\n",
    "    image_to_print = mask_image(mask, raw_image)\n",
    "    image_to_print = image_to_print.squeeze().permute(1,2,0) \n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image_to_print)\n",
    "    plt.title(f\"Segmentation Mask {i+1}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
