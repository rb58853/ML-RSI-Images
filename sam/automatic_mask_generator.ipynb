{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7237c062",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rb58853/images_RIS-ML-Conv-NLP/blob/main/sam/automatic_mask_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7c0041e",
      "metadata": {
        "id": "b7c0041e"
      },
      "source": [
        "# Automatically generating object masks with SAM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "289bb0b4",
      "metadata": {
        "id": "289bb0b4"
      },
      "source": [
        "Since SAM can efficiently process prompts, masks for the entire image can be generated by sampling a large number of prompts over an image. This method was used to generate the dataset SA-1B.\n",
        "\n",
        "The class `SamAutomaticMaskGenerator` implements this capability. It works by sampling single-point input prompts in a grid over the image, from each of which SAM can predict multiple masks. Then, masks are filtered for quality and deduplicated using non-maximal suppression. Additional options allow for further improvement of mask quality and quantity, such as running prediction on multiple crops of the image or postprocessing masks to remove small disconnected regions and holes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "072e25b8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 41
        },
        "id": "072e25b8",
        "outputId": "d8928605-6a5a-479a-c4dc-1d2d290c19b9"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, HTML\n",
        "display(HTML(\n",
        "\"\"\"\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/facebookresearch/segment-anything/blob/main/notebooks/automatic_mask_generator_example.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\"\"\"\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0b71431",
      "metadata": {
        "id": "c0b71431"
      },
      "source": [
        "## Environment Set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0685a2f5",
      "metadata": {
        "id": "0685a2f5"
      },
      "outputs": [],
      "source": [
        "using_colab = True\n",
        "\n",
        "if using_colab:\n",
        "    import torch\n",
        "    import torchvision\n",
        "    print(\"PyTorch version:\", torch.__version__)\n",
        "    print(\"Torchvision version:\", torchvision.__version__)\n",
        "    print(\"CUDA is available:\", torch.cuda.is_available())\n",
        "    import sys\n",
        "    !{sys.executable} -m pip install opencv-python matplotlib\n",
        "    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
        "\n",
        "    !mkdir images\n",
        "    !wget -P images https://raw.githubusercontent.com/facebookresearch/segment-anything/main/notebooks/images/dog.jpg\n",
        "\n",
        "    !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd2bc687",
      "metadata": {
        "id": "fd2bc687"
      },
      "source": [
        "## Set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "560725a2",
      "metadata": {
        "id": "560725a2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74b6e5f0",
      "metadata": {
        "id": "74b6e5f0"
      },
      "outputs": [],
      "source": [
        "def show_anns(anns):\n",
        "    if len(anns) == 0:\n",
        "        return\n",
        "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
        "    ax = plt.gca()\n",
        "    ax.set_autoscale_on(False)\n",
        "\n",
        "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
        "    img[:,:,3] = 0\n",
        "    for ann in sorted_anns:\n",
        "        m = ann['segmentation']\n",
        "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
        "        img[m] = color_mask\n",
        "    ax.imshow(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27c41445",
      "metadata": {
        "id": "27c41445"
      },
      "source": [
        "## Example image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad354922",
      "metadata": {
        "id": "ad354922"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "img_url = '/content/2.jpg'\n",
        "raw_image = Image.open(img_url).convert(\"RGB\")\n",
        "image = cv2.imread(img_url)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0ac8c67",
      "metadata": {
        "id": "e0ac8c67"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8c2824a",
      "metadata": {
        "id": "b8c2824a"
      },
      "source": [
        "## Automatic mask generation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9ef74c5",
      "metadata": {
        "id": "d9ef74c5"
      },
      "source": [
        "To run automatic mask generation, provide a SAM model to the `SamAutomaticMaskGenerator` class. Set the path below to the SAM checkpoint. Running on CUDA and with the default model is recommended."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1848a108",
      "metadata": {
        "id": "1848a108"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
        "\n",
        "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
        "model_type = \"vit_h\"\n",
        "\n",
        "device = \"cuda\"\n",
        "\n",
        "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "sam.to(device=device)\n",
        "\n",
        "mask_generator = SamAutomaticMaskGenerator(sam)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6b1ea21",
      "metadata": {
        "id": "d6b1ea21"
      },
      "source": [
        "To generate masks, just run `generate` on an image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "391771c1",
      "metadata": {
        "id": "391771c1"
      },
      "outputs": [],
      "source": [
        "masks = mask_generator.generate(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e36a1a39",
      "metadata": {
        "id": "e36a1a39"
      },
      "source": [
        "Mask generation returns a list over masks, where each mask is a dictionary containing various data about the mask. These keys are:\n",
        "* `segmentation` : the mask\n",
        "* `area` : the area of the mask in pixels\n",
        "* `bbox` : the boundary box of the mask in XYWH format\n",
        "* `predicted_iou` : the model's own prediction for the quality of the mask\n",
        "* `point_coords` : the sampled input point that generated this mask\n",
        "* `stability_score` : an additional measure of mask quality\n",
        "* `crop_box` : the crop of the image used to generate this mask in XYWH format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fae8d66",
      "metadata": {
        "id": "4fae8d66"
      },
      "outputs": [],
      "source": [
        "print(len(masks))\n",
        "print(masks[0].keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53009a1f",
      "metadata": {
        "id": "53009a1f"
      },
      "source": [
        "Show all the masks overlayed on the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77ac29c5",
      "metadata": {
        "id": "77ac29c5",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(image)\n",
        "show_anns(masks)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00b3d6b2",
      "metadata": {
        "id": "00b3d6b2"
      },
      "source": [
        "## Automatic mask generation options"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "183de84e",
      "metadata": {
        "id": "183de84e"
      },
      "source": [
        "There are several tunable parameters in automatic mask generation that control how densely points are sampled and what the thresholds are for removing low quality or duplicate masks. Additionally, generation can be automatically run on crops of the image to get improved performance on smaller objects, and post-processing can remove stray pixels and holes. Here is an example configuration that samples more masks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68364513",
      "metadata": {
        "id": "68364513"
      },
      "outputs": [],
      "source": [
        "mask_generator_2 = SamAutomaticMaskGenerator(\n",
        "    model=sam,\n",
        "    points_per_side=32,\n",
        "    pred_iou_thresh=0.86,\n",
        "    stability_score_thresh=0.92,\n",
        "    crop_n_layers=1,\n",
        "    crop_n_points_downscale_factor=2,\n",
        "    min_mask_region_area=100,  # Requires open-cv to run post-processing\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bebcdaf1",
      "metadata": {
        "id": "bebcdaf1"
      },
      "outputs": [],
      "source": [
        "masks2 = mask_generator_2.generate(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8473f3c",
      "metadata": {
        "id": "b8473f3c"
      },
      "outputs": [],
      "source": [
        "len(masks2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb702ae3",
      "metadata": {
        "id": "fb702ae3"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(image)\n",
        "show_anns(masks2)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38880a3c",
      "metadata": {
        "id": "38880a3c"
      },
      "source": [
        "## Create image from mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c937160",
      "metadata": {
        "id": "8c937160"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def mask_image(mask, raw_image):\n",
        "    weigth, heigth = raw_image.size\n",
        "    new_image = Image.new('RGBA', (weigth, heigth), (0, 0, 0, 0))\n",
        "\n",
        "    original_pixles = raw_image.load()\n",
        "    pixels = new_image.load()\n",
        "\n",
        "    for i in range (heigth):\n",
        "        for j in range (weigth):\n",
        "            if mask[i,j]:\n",
        "                pixels[j, i] = original_pixles[j,i]\n",
        "            else:\n",
        "                pass\n",
        "    return new_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fc7414e",
      "metadata": {
        "id": "3fc7414e"
      },
      "outputs": [],
      "source": [
        "def bbox_image(bbox, image):\n",
        "    x,y,w,h =  bbox[0],bbox[1],bbox[2],bbox[3]\n",
        "    return image[y:y+h, x:x+w]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "225b85ed",
      "metadata": {
        "id": "225b85ed"
      },
      "source": [
        "### test cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9592a7b3",
      "metadata": {
        "id": "9592a7b3"
      },
      "outputs": [],
      "source": [
        "_masks = masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e68b3e1",
      "metadata": {
        "id": "4e68b3e1"
      },
      "outputs": [],
      "source": [
        "_masks = masks2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc6cb2c5",
      "metadata": {
        "id": "dc6cb2c5"
      },
      "outputs": [],
      "source": [
        "images_box= []\n",
        "images_mask= []\n",
        "\n",
        "for mask in _masks:\n",
        "    images_box.append(bbox_image(mask['bbox'],image))\n",
        "    images_mask.append(mask_image(mask['segmentation'], raw_image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-WeTlY_z26WP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WeTlY_z26WP",
        "outputId": "db40c208-f6b4-4e0a-de97-c704f88097e0"
      },
      "outputs": [],
      "source": [
        "print(len(images_mask))\n",
        "print(len(images_box))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0077379d",
      "metadata": {
        "id": "0077379d"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "for im in images_mask:\n",
        "    display(im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85fa04ff",
      "metadata": {
        "id": "85fa04ff"
      },
      "outputs": [],
      "source": [
        "for im in images_box:\n",
        "    plt.figure(figsize=(3,3))\n",
        "    plt.imshow(im)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
