{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ihGoIYnhbPL",
        "outputId": "c713e823-4df4-4499-aa0e-7ddbc25ae6f7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2DLBfg7YFOC"
      },
      "outputs": [],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "QWpjB8hPYFOI"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "url = \"/content/drive/MyDrive/Tesis/Clip_tests/2.jpg\"\n",
        "image = Image.open(url)\n",
        "\n",
        "inputs = processor(text=[\"two cats lying in a sofa next to a TV control\", \"a cat with a knife on the neck of a lying down dog\",\"a cat and a dog lying together in a sofa\"], images=image, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "outputs = model(**inputs)\n",
        "logits_per_image = outputs.logits_per_image  # this is the image-text similarity score\n",
        "probs = logits_per_image.softmax(dim=1)  # we can take the softmax to get the label probabilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3eN7ulTYFOH"
      },
      "source": [
        "#### basic clip usecase"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3477TQTlaJr9",
        "outputId": "f754a21e-c379-4fa2-811d-504050fb4267"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.7325e-04, 9.9870e-01, 1.1233e-03]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}