{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rb58853/images_RIS-ML-Conv-NLP/blob/main/clip_caption/caption_from_image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ihGoIYnhbPL",
        "outputId": "65796f5d-291e-45be-dec8-cccec09ded6a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2DLBfg7YFOC"
      },
      "outputs": [],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QWpjB8hPYFOI",
        "outputId": "537329f4-c63b-49e3-9472-1d08d5eccc71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[7.6902e-01, 2.3812e-05, 1.8701e-01, 4.3945e-02]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "_images = []\n",
        "\n",
        "url = \"/content/drive/MyDrive/Tesis/Clip_tests/1.jpg\"\n",
        "_images.append(Image.open(url))\n",
        "url = \"/content/drive/MyDrive/Tesis/Clip_tests/brad.jpg\"\n",
        "_images.append(Image.open(url))\n",
        "url = \"/content/drive/MyDrive/Tesis/Clip_tests/messi.jpg\"\n",
        "_images.append(Image.open(url))\n",
        "url = \"/content/drive/MyDrive/Tesis/Clip_tests/ronaldo.jpg\"\n",
        "_images.append(Image.open(url))\n",
        "\n",
        "inputs = processor(text=[\"two cats playing futbol\"], images=_images, return_tensors=\"pt\", padding=True)\n",
        "outputs = model(**inputs)\n",
        "\n",
        "logits_per_text = outputs.logits_per_text  # this is the image-text similarity score\n",
        "probs = logits_per_text.softmax(dim=1)  # we can take the softmax to get the label probabilities\n",
        "\n",
        "print(probs)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}