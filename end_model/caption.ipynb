{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rb58853/images_RIS-ML-Conv-NLP/blob/main/end_model/caption.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "vscode": {
          "languageId": "bat"
        },
        "id": "TnVhTeQkdLdO",
        "outputId": "6407898d-cbf5-474f-8b79-45b1534276bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6OaGHeSdLdT"
      },
      "source": [
        "## Import librarys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gY5w4189dLdU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jp5bLjhidLdV"
      },
      "source": [
        "### Load Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "W32WdDIddLdV"
      },
      "outputs": [],
      "source": [
        "img_url = '/content/2.jpg'\n",
        "raw_image = Image.open(img_url).convert(\"RGB\")\n",
        "image = cv2.imread(img_url)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ4vpueydLdW"
      },
      "source": [
        "# Load all Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0V5u9_PXdLdW"
      },
      "source": [
        "## Segment Anything Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PZaNgE4LdLdX",
        "outputId": "426abff6-f04c-48bf-ce7f-1dc70749c681",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.1.0+cu118\n",
            "Torchvision version: 0.16.0+cu118\n",
            "CUDA is available: True\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Collecting git+https://github.com/facebookresearch/segment-anything.git\n",
            "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-pn5t7qbm\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-pn5t7qbm\n",
            "  Resolved https://github.com/facebookresearch/segment-anything.git to commit 6fdee8f2727f4506cfbbe553e23b895e27956588\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "--2023-10-26 15:50:14--  https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 99.84.238.181, 99.84.238.206, 99.84.238.162, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|99.84.238.181|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2564550879 (2.4G) [binary/octet-stream]\n",
            "Saving to: ‘sam_vit_h_4b8939.pth.3’\n",
            "\n",
            "sam_vit_h_4b8939.pt 100%[===================>]   2.39G   227MB/s    in 15s     \n",
            "\n",
            "2023-10-26 15:50:29 (169 MB/s) - ‘sam_vit_h_4b8939.pth.3’ saved [2564550879/2564550879]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"Torchvision version:\", torchvision.__version__)\n",
        "print(\"CUDA is available:\", torch.cuda.is_available())\n",
        "import sys\n",
        "!{sys.executable} -m pip install opencv-python matplotlib\n",
        "!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
        "!wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
        "\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
        "\n",
        "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
        "model_type = \"vit_h\"\n",
        "\n",
        "device = \"cuda\"\n",
        "\n",
        "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "sam.to(device=device)\n",
        "\n",
        "mask_generator = SamAutomaticMaskGenerator(sam)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UlxZN6-dLdX"
      },
      "source": [
        "#### Create image from mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ivl0wnEDdLdY"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def mask_image(mask, raw_image):\n",
        "    weigth, heigth = raw_image.size\n",
        "    new_image = Image.new('RGBA', (weigth, heigth), (0, 0, 0, 0))\n",
        "\n",
        "    original_pixles = raw_image.load()\n",
        "    pixels = new_image.load()\n",
        "\n",
        "    for i in range (heigth):\n",
        "        for j in range (weigth):\n",
        "            if mask[i,j]:\n",
        "                pixels[j, i] = original_pixles[j,i]\n",
        "            else:\n",
        "                pass\n",
        "    return new_image\n",
        "\n",
        "def bbox_image(bbox, image):\n",
        "    x,y,w,h =  bbox[0],bbox[1],bbox[2],bbox[3]\n",
        "    return image[y:y+h, x:x+w]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WsWiSrhCdLdY"
      },
      "outputs": [],
      "source": [
        "def all_areas_from_image(image, raw_image):\n",
        "    masks = mask_generator.generate(image)\n",
        "    images_box= []\n",
        "    images_mask= []\n",
        "    for mask in masks:\n",
        "        images_box.append(bbox_image(mask['bbox'],image))\n",
        "        images_mask.append(mask_image(mask['segmentation'], raw_image))\n",
        "    return {'box':images_box, 'mask':images_mask}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7woGwmzdLdZ"
      },
      "source": [
        "## BLIP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vGpRT3RXdLdZ"
      },
      "outputs": [],
      "source": [
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "\n",
        "blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\").to(\"cuda\")\n",
        "\n",
        "def blip (_image):\n",
        "    inputs = blip_processor(_image, return_tensors=\"pt\").to(\"cuda\")\n",
        "    out = blip_model.generate(**inputs)\n",
        "    result = blip_processor.decode(out[0], skip_special_tokens=True)\n",
        "    return result\n",
        "\n",
        "def all_captions(image, raw_image):\n",
        "    # areas = all_areas_from_image(image, raw_image)['mask']\n",
        "    areas = all_areas_from_image(image, raw_image)['box']\n",
        "    origin = str(blip(raw_image))\n",
        "    captions = [origin]\n",
        "    for im in areas:\n",
        "        captions.append(origin +\" \"+ str(blip(im)))\n",
        "    return captions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPlHAjTbdLdZ"
      },
      "source": [
        "## CLIP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xNZ9Qw3mdLda"
      },
      "outputs": [],
      "source": [
        "from transformers import CLIPProcessor, CLIPModel\n",
        "\n",
        "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "clip_model = clip_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "UwS4AgTVdLda"
      },
      "outputs": [],
      "source": [
        "def select_caption(captions, image):\n",
        "    inputs = clip_processor(text=captions, images=image, return_tensors=\"pt\", padding=True)\n",
        "    inputs = {name: tensor.to(device) for name, tensor in inputs.items()}\n",
        "    outputs = clip_model(**inputs)\n",
        "\n",
        "    logits_per_image = outputs.logits_per_image  # this is the image-text similarity score\n",
        "    probs = logits_per_image.softmax(dim=1)\n",
        "    print(probs)\n",
        "    return select_from_probs(probs, captions)\n",
        "\n",
        "def select_from_probs(probs, captions):\n",
        "    max_prob = 0\n",
        "    index = 0\n",
        "    for i,prob in zip(range(len(probs[0])),probs[0]):\n",
        "        if prob > max_prob:\n",
        "            max_prob = prob\n",
        "            index = i\n",
        "    return captions[index]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0T2tjeQdLda"
      },
      "source": [
        "# Run Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Ze7wHoYydLda",
        "outputId": "3c2d8fb6-b501-4482-d539-f3e2a6e5d744",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "there is a cat and a dog laying on a bed together\n",
            "there is a cat and a dog laying on a bed together there is a cat that is laying down on a bed\n",
            "there is a cat and a dog laying on a bed together there is a cat that is sitting on a bed with a pillow\n",
            "there is a cat and a dog laying on a bed together there is a cat that is sitting on a bed with a blanket\n",
            "there is a cat and a dog laying on a bed together there is a cat that is sitting in a bowl of food\n",
            "there is a cat and a dog laying on a bed together there are two cats that are sitting together in a red chair\n",
            "there is a cat and a dog laying on a bed together a close up of a cat with a blurry background\n",
            "there is a cat and a dog laying on a bed together blurry image of a cat sitting in a room with a red wall\n",
            "there is a cat and a dog laying on a bed together there is a close up of a person eating a piece of food\n",
            "there is a cat and a dog laying on a bed together there is a black cat sitting on a table next to a laptop\n",
            "there is a cat and a dog laying on a bed together there is a close up of a person with a tooth brush\n",
            "there is a cat and a dog laying on a bed together araffe and a cat laying on a couch with scissors\n",
            "there is a cat and a dog laying on a bed together blurry photo of a cat sitting on a bed with a red blanket\n",
            "there is a cat and a dog laying on a bed together blurry image of a close up of a person's eye\n",
            "there is a cat and a dog laying on a bed together there is a cat and a dog laying on a couch together\n",
            "there is a cat and a dog laying on a bed together there is a blurry photo of a person holding a cell phone\n",
            "there is a cat and a dog laying on a bed together there is a cat that is sitting on a bed with a blanket\n",
            "there is a cat and a dog laying on a bed together there is a blurry photo of a person holding a cell phone\n",
            "there is a cat and a dog laying on a bed together there is a cat that is sitting on a couch with a banana\n",
            "there is a cat and a dog laying on a bed together there is a banana that is sitting on a table\n",
            "there is a cat and a dog laying on a bed together there is a banana that is sitting on a table\n",
            "there is a cat and a dog laying on a bed together blurred image of a close up of a person's eye\n",
            "there is a cat and a dog laying on a bed together a close up of a person with a red shirt and a white shirt\n",
            "there is a cat and a dog laying on a bed together there is a blurry photo of a toothbrush with a tooth brush in it\n",
            "there is a cat and a dog laying on a bed together blurry photograph of a woman with long hair and a red shirt\n",
            "there is a cat and a dog laying on a bed together there is a cat that is sitting on a bed with a blanket\n",
            "there is a cat and a dog laying on a bed together blurry image of a cat sitting on a bench in a park\n",
            "there is a cat and a dog laying on a bed together there is a piece of bread on a cutting board on the table\n",
            "there is a cat and a dog laying on a bed together blurry photo of a cat laying on a bed with a remote control\n",
            "there is a cat and a dog laying on a bed together blurry image of a blurry image of a person holding a cell phone\n",
            "there is a cat and a dog laying on a bed together there is a blue ball sitting on a table next to a banana\n",
            "there is a cat and a dog laying on a bed together blurry photo of a car with a red light on it\n",
            "there is a cat and a dog laying on a bed together there is a blurry photo of a person holding a cell phone\n",
            "there is a cat and a dog laying on a bed together blurred image of a red and black background with a blurry image of a person\n",
            "there is a cat and a dog laying on a bed together blurry image of a cat with a long tail and a long tail\n",
            "there is a cat and a dog laying on a bed together blurry image of a person with a hand on a phone\n",
            "there is a cat and a dog laying on a bed together there is a bird that is sitting on a wooden floor\n",
            "there is a cat and a dog laying on a bed together there is a blurry photo of a white and black cat\n",
            "there is a cat and a dog laying on a bed together there is a small bird sitting on a branch in the air\n",
            "there is a cat and a dog laying on a bed together blurred image of a blurry image of a bird on a beach\n",
            "there is a cat and a dog laying on a bed together there is a cat that is sitting on a bed with a blanket\n",
            "there is a cat and a dog laying on a bed together someone is holding a blue ball in their hand\n",
            "there is a cat and a dog laying on a bed together there is a blurry photo of a man wearing a hat\n",
            "there is a cat and a dog laying on a bed together there is a blurry photo of a person in bed with a teddy bear\n",
            "there is a cat and a dog laying on a bed together purple and red background with a small white flower\n"
          ]
        }
      ],
      "source": [
        "captions = all_captions(image, raw_image)\n",
        "captions.append(\"there is a cat and a dog laying on a bed together knife\")\n",
        "for caption in captions:\n",
        "    print(caption)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = select_caption(captions, raw_image)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "b0PH0_GZfPp0",
        "outputId": "8e58866c-4b70-4076-972e-04fc4f3fb4f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6.5799e-04, 1.0727e-03, 7.7942e-04, 8.3541e-04, 1.4952e-04, 6.5678e-04,\n",
            "         9.6113e-03, 4.0556e-03, 4.6645e-03, 6.0604e-05, 1.6062e-02, 3.3200e-02,\n",
            "         1.0789e-03, 1.8120e-02, 2.9229e-04, 1.6059e-02, 8.3541e-04, 1.6059e-02,\n",
            "         2.1157e-04, 1.2755e-04, 1.2755e-04, 1.9606e-02, 1.8862e-03, 3.6882e-02,\n",
            "         9.2014e-04, 8.3541e-04, 2.9504e-03, 1.7574e-04, 1.6400e-03, 7.2747e-03,\n",
            "         3.1296e-05, 1.5634e-03, 1.6059e-02, 1.4272e-03, 1.3489e-02, 1.3496e-02,\n",
            "         2.7279e-04, 3.1320e-04, 1.1643e-03, 5.2064e-03, 8.3541e-04, 4.5606e-04,\n",
            "         3.4663e-04, 7.6761e-04, 1.1672e-04, 7.4757e-01]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "there is a cat and a dog laying on a bed together knife\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}